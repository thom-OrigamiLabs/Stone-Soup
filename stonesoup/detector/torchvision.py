from typing import Callable

import numpy as np
try:
    import torch
    from torchvision.ops import nms
except ImportError as error:
    raise ImportError(
        "Usage of the Torchvision detectors requires that Pytorch and Torchvision "
        "are installed. A quick guide on how to set these up can be found here: "
        "https://pytorch.org/get-started/locally/")\
        from error

from ._video import _VideoAsyncBoxDetector
from ..base import Property
from ..types.array import StateVector
from ..types.detection import Detection
import time
import enum
class TorchvisionBoxObjectDetector(_VideoAsyncBoxDetector):
    """TorchvisionBoxObjectDetector

    A box object detector that generates detections of objects in the form of bounding boxes 
    from image/video frames using a Torchvision object detection model. 
    
    The detections generated by the box detector have the form of bounding boxes that capture 
    the area of the frame where an object is detected. Each bounding box is represented by a 
    vector of the form ``[x, y, w, h]``, where ``x, y`` denote the relative coordinates of the 
    top-left corner, while ``w, h`` denote the relative width and height of the bounding box. 
    
    Additionally, each detection carries the following meta-data fields:

    - ``raw_box``: The raw bounding box, as generated by TensorFlow.
    - ``class``: A dict with keys ``id`` and ``name`` relating to the id and name of the 
      detection class.
    - ``score``: A float in the range ``(0, 1]`` indicating the detector's confidence.
    
    Important
    ---------
    Use of the Torchvision detectors requires that Pytorch and Torchvision
    are installed. A quick guide on how to set these up can be found
    `here <https://pytorch.org/get-started/locally/>`_. 
    
    """  # noqa

    net: Callable = Property(doc="Torchvision model creation function")
    net_weights: enum.Enum = Property(doc="Torchvision weights corresponding to the net model (e.g. SSD300_VGG16_Weights.DEFAULT)")
    use_cuda: bool = Property(doc="Use GPU (where available)", default=True)
    use_fp16: bool = Property(doc="Use half precision for greater speed at the loss of accuracy. Requires CUDA.", default=False)
    use_nms: bool = Property(doc="Use non-maxima supression.", default=False)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # Set up model
        model = self.net(weights=self.net_weights, box_score_thresh=0.0)
        model.eval()
        if self.use_cuda and torch.cuda.is_available():
            model.cuda()
        else:
            # If we aren;t using CUDA, turn FP16 off
            self.use_fp16 = False
        if self.use_fp16:
            model.half()
        # Set the inference function
        self._detect_fn = model
        
        # Define the preprocessing function
        preprocess = self.net_weights.transforms()
        self._preprocess_fn = preprocess
        
        # Extract the classes
        classes = self.net_weights.value.meta['categories']
        self.category_index = {}
        for i,l in enumerate(classes):
            self.category_index[i] = {'id':i,'name':l}
                
       

    def _get_detections_from_frame(self, frame):
        # Convert numpy array to tensor
        rgb_tensor = torch.tensor(np.transpose(frame.pixels,[2,0,1]))
        # Preprocess it
        batch = self._preprocess_fn(rgb_tensor)
        
        # Move to GPU if needed
        if self.use_cuda:
            batch = batch.cuda()
        if self.use_fp16:
            batch = batch.half()
        # Make the prediction
        prediction = self._detect_fn([batch])[0] # single frame at the moment
        
        # Perform non-max supression or not
        if self.use_nms:
            keep_idx = nms(prediction["boxes"], prediction['scores'], 0.4)
        else:
            keep_idx = np.ones(prediction['scores'].size(),dtype=bool)
            
        # Pull results to CPU
        nboxes = prediction["boxes"][keep_idx].cpu().detach().numpy() # normalised boxes (placeholder, normalised later)
        classes = prediction['labels'][keep_idx].cpu().detach().numpy()
        scores = prediction['scores'][keep_idx].cpu().detach().numpy()
        boxes = nboxes.astype(int)
        
        # Form detections
        detections = set()
        frame_height, frame_width, _ = frame.pixels.shape
        
        # convert to relative boxes (0-1)
        nboxes[:,0] /= frame_width
        nboxes[:,1] /= frame_height
        nboxes[:,2] /= frame_width
        nboxes[:,3] /= frame_height
        
        for box, nbox, class_, score in zip(boxes, nboxes, classes, scores):
            metadata = {
                "raw_box": nbox, # normalised x0 y0 x1 y1
                "class": self.category_index[class_],
                "score": score,
            }
            # Transform box to be in format (x, y, w, h)
            state_vector = StateVector([box[0],
                                        box[1],
                                        (box[2] - box[0]),
                                        (box[3] - box[1])])
            detection = Detection(state_vector=state_vector,
                                  timestamp=frame.timestamp,
                                  metadata=metadata)
            detections.add(detection)
        

        return detections

