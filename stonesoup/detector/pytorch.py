from pathlib import Path
import time
import numpy as np
try:
    import torch
    from .detector_wrapper import GenericBoxObjectWrapper
    from torchvision.ops import nms
except ImportError as error:
    # TODO
    raise ImportError(
        "Usage of the TensorFlow detectors requires that TensorFlow and the TensorFlow Object "
        "Detection API  are installed. A quick guide on how to set these up can be found here: "
        "https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html")\
        from error

from ._video import _VideoAsyncBoxDetector
from ..base import Property
from ..types.array import StateVector
from ..types.detection import Detection


class PyTorchBoxObjectDetector(_VideoAsyncBoxDetector):
    """TensorFlowBoxObjectDetector

    A box object detector that generates detections of objects in the form of bounding boxes 
    from image/video frames using a TensorFlow object detection model. Both TensorFlow 1 and 
    TensorFlow 2 compatible models are supported.
    
    The detections generated by the box detector have the form of bounding boxes that capture 
    the area of the frame where an object is detected. Each bounding box is represented by a 
    vector of the form ``[x, y, w, h]``, where ``x, y`` denote the relative coordinates of the 
    top-left corner, while ``w, h`` denote the relative width and height of the bounding box. 
    
    Additionally, each detection carries the following meta-data fields:

    - ``raw_box``: The raw bounding box, as generated by TensorFlow.
    - ``class``: A dict with keys ``id`` and ``name`` relating to the id and name of the 
      detection class.
    - ``score``: A float in the range ``(0, 1]`` indicating the detector's confidence.
    
    Important
    ---------
    Use of this class requires that TensorFlow 2 and the TensorFlow Object Detection API are 
    installed. A quick guide on how to set these up can be found 
    `here <https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html>`_. 
    
    """  # noqa

    model: GenericBoxObjectWrapper = Property(
        doc="Path to ``saved_model`` directory. This is the directory that contains the "
            "``saved_model.pb`` file.")


    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        self._preprocess_fn = self.model.preprocess_fn
        self._detect_fn = self.model.detect_fn
        self._postprocess_fn = self.model.postprocess_fn
        self.category_index = self.model.category_index
       

    def _get_detections_from_frame(self, frame):
        # preprocess needs to convert to tensor and transpose
        # rgb_tensor = torch.tensor(np.transpose(frame.pixels,[2,0,1]))
        
        inp = self._preprocess_fn(frame.pixels)
        prediction = self._detect_fn(inp)
        prediction = self._postprocess_fn(prediction)
        
        keep_idx = nms(prediction["boxes"], prediction['scores'], 0.4)
        nboxes = prediction["boxes"][keep_idx].cpu().detach().numpy()
        boxes = nboxes.astype(int)
        classes = prediction['labels'][keep_idx].cpu().detach().numpy()
        scores = prediction['scores'][keep_idx].cpu().detach().numpy()
        
        # No NMS
        # nboxes = prediction["boxes"].cpu().detach().numpy()
        # boxes = nboxes.astype(int)
        # classes = prediction['labels'].cpu().detach().numpy()
        # scores = prediction['scores'].cpu().detach().numpy()
        
        # Form detections
        detections = set()
        frame_height, frame_width, _ = frame.pixels.shape
        
        # convert to relative boxes
        nboxes[:,0] /= frame_width
        nboxes[:,1] /= frame_height
        nboxes[:,2] /= frame_width
        nboxes[:,3] /= frame_height
        
        for box, nbox, class_, score in zip(boxes, nboxes, classes, scores):
            metadata = {
                "raw_box": nbox, # normalised x0 y0 x1 y1
                "class": self.category_index[class_],
                "score": score,
            }
            # Transform box to be in format (x, y, w, h)
            state_vector = StateVector([box[0],
                                        box[1],
                                        (box[2] - box[0]),
                                        (box[3] - box[1])])
            detection = Detection(state_vector=state_vector,
                                  timestamp=frame.timestamp,
                                  metadata=metadata)
            detections.add(detection)
        
        return detections

